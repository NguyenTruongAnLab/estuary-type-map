#!/usr/bin/env python3
"""
Manage Large Files for GitHub Repository
========================================

PURPOSE: Automatically manage files >50MB to prevent GitHub push failures
- Scans repository for files larger than 50MB
- Adds them to .gitignore (with patterns and specific paths)
- Untracks them from git if already committed
- Prepares list for GitHub release attachment

USAGE:
    python scripts/manage_large_files.py

Author: Global Water Body Surface Area Atlas Project
Date: October 14, 2025
"""

import os
import subprocess
from pathlib import Path
import json
from datetime import datetime

# Configuration
MAX_FILE_SIZE_MB = 30  # Updated to 30MB limit
MAX_FILE_SIZE_BYTES = MAX_FILE_SIZE_MB * 1024 * 1024
BASE_DIR = Path(__file__).resolve().parent.parent

# Files to always ignore (common large file patterns)
IGNORE_PATTERNS = [
    "# Large files (auto-generated by manage_large_files.py)",
    "*.gpkg",
    "*.nc", 
    "*.parquet",
    "*.h5",
    "*.hdf5",
    "*.zip",
    "*.tar.gz",
    "*.7z",
    "diagnostics_html/*.html",
    "data/processed/*.gpkg",
    "data/raw/**/*.gpkg", 
    "data/raw/**/*.nc",
    "**/*_large.*",
    "**/*_heavy.*",
    # GeoJSON and HTML files over 30MB
    "**/*.geojson",
    "**/*.html"
]

def get_file_size_mb(file_path):
    """Get file size in MB"""
    try:
        return os.path.getsize(file_path) / (1024 * 1024)
    except (OSError, FileNotFoundError):
        return 0

def run_git_command(command):
    """Run git command and return output"""
    try:
        result = subprocess.run(
            command, 
            shell=True, 
            cwd=BASE_DIR,
            capture_output=True, 
            text=True
        )
        return result.returncode == 0, result.stdout.strip(), result.stderr.strip()
    except Exception as e:
        return False, "", str(e)

def find_large_files():
    """Find all files larger than MAX_FILE_SIZE_MB"""
    print(f"\nüîç Scanning repository for files larger than {MAX_FILE_SIZE_MB} MB...")
    
    large_files = []
    
    # Walk through all files in the repository
    for root, dirs, files in os.walk(BASE_DIR):
        # Skip .git directory
        if '.git' in dirs:
            dirs.remove('.git')
        
        for file in files:
            file_path = Path(root) / file
            relative_path = file_path.relative_to(BASE_DIR)
            
            size_mb = get_file_size_mb(file_path)
            if size_mb > MAX_FILE_SIZE_MB:
                large_files.append({
                    'path': str(relative_path),
                    'absolute_path': str(file_path),
                    'size_mb': round(size_mb, 1),
                    'size_bytes': file_path.stat().st_size
                })
    
    # Sort by size (largest first)
    large_files.sort(key=lambda x: x['size_mb'], reverse=True)
    
    print(f"   Found {len(large_files)} files > {MAX_FILE_SIZE_MB} MB:")
    for file_info in large_files:
        print(f"     {file_info['path']} ({file_info['size_mb']} MB)")
    
    return large_files

def update_gitignore(large_files):
    """Update .gitignore with large files and patterns"""
    print(f"\nüìù Updating .gitignore...")
    
    gitignore_path = BASE_DIR / '.gitignore'
    
    # Read existing .gitignore
    existing_lines = []
    if gitignore_path.exists():
        with open(gitignore_path, 'r', encoding='utf-8') as f:
            existing_lines = [line.rstrip() for line in f.readlines()]
    
    # Prepare new lines to add
    new_lines = []
    
    # Add header if not exists
    header = "# Large files (auto-generated by manage_large_files.py)"
    if header not in existing_lines:
        new_lines.extend([
            "",
            header,
            f"# Files larger than {MAX_FILE_SIZE_MB}MB (generated {datetime.now().strftime('%Y-%m-%d %H:%M')})"
        ])
    
    # Add patterns if not exists
    for pattern in IGNORE_PATTERNS[1:]:  # Skip header
        if pattern not in existing_lines:
            new_lines.append(pattern)
    
    # Add specific large files
    files_added = 0
    for file_info in large_files:
        file_path = file_info['path'].replace('\\', '/')  # Use forward slashes
        if file_path not in existing_lines and not any(file_path in line for line in existing_lines):
            new_lines.append(file_path)
            files_added += 1
    
    # Write updated .gitignore
    if new_lines:
        with open(gitignore_path, 'a', encoding='utf-8') as f:
            f.write('\n'.join(new_lines) + '\n')
        print(f"   Added {files_added} large files and {len(IGNORE_PATTERNS)-1} patterns to .gitignore")
    else:
        print("   .gitignore is already up to date")

def untrack_large_files(large_files):
    """Remove large files from git tracking if they are currently tracked"""
    print(f"\nüóëÔ∏è  Checking for tracked large files...")
    
    # Get list of tracked files
    success, tracked_output, _ = run_git_command("git ls-files")
    if not success:
        print("   ‚ö†Ô∏è Could not get list of tracked files")
        return
    
    tracked_files = set(tracked_output.split('\n'))
    
    untracked_count = 0
    for file_info in large_files:
        file_path = file_info['path'].replace('\\', '/')  # Git uses forward slashes
        
        if file_path in tracked_files:
            print(f"   Untracking: {file_path}")
            success, _, error = run_git_command(f'git rm --cached "{file_path}"')
            if success:
                untracked_count += 1
            else:
                print(f"     ‚ö†Ô∏è Failed to untrack {file_path}: {error}")
    
    if untracked_count > 0:
        print(f"   ‚úÖ Untracked {untracked_count} large files from git")
    else:
        print(f"   ‚úÖ No large files were being tracked")

def create_release_manifest(large_files):
    """Create manifest for GitHub release attachment"""
    print(f"\nüì¶ Creating release manifest...")
    
    manifest = {
        'generated': datetime.now().isoformat(),
        'description': f'Large files (>{MAX_FILE_SIZE_MB}MB) for GitHub release attachment',
        'total_files': len(large_files),
        'total_size_mb': sum(f['size_mb'] for f in large_files),
        'files': large_files
    }
    
    manifest_path = BASE_DIR / 'release_artifacts_manifest.json'
    with open(manifest_path, 'w', encoding='utf-8') as f:
        json.dump(manifest, f, indent=2)
    
    print(f"   ‚úÖ Created manifest: release_artifacts_manifest.json")
    print(f"   üìä Total: {len(large_files)} files, {manifest['total_size_mb']:.1f} MB")
    
    return manifest_path

def create_release_script(large_files):
    """Create script to attach files to GitHub release"""
    print(f"\nüöÄ Creating GitHub release script...")
    
    script_content = f"""#!/usr/bin/env python3
\"\"\"
GitHub Release with Large Files Attachment
=========================================

Auto-generated script to create GitHub release v1.0.0 with large file attachments

Usage: python attach_large_files_to_release.py
\"\"\"

import subprocess
import sys
from pathlib import Path

BASE_DIR = Path(__file__).resolve().parent
RELEASE_TAG = "v1.0.0"
RELEASE_TITLE = "v1.0.0 - High-Resolution Global Tidal Basin Atlas"

# Large files to attach (generated {datetime.now().strftime('%Y-%m-%d %H:%M')})
LARGE_FILES = [
"""
    
    for file_info in large_files:
        script_content += f"    {{\n"
        script_content += f"        'path': r\"{file_info['absolute_path']}\",\n"
        script_content += f"        'name': \"{Path(file_info['path']).name}\",\n"
        script_content += f"        'size_mb': {file_info['size_mb']}\n"
        script_content += f"    }},\n"
    
    script_content += f"""]

def run_command(command):
    \"\"\"Run shell command\"\"\"
    try:
        result = subprocess.run(command, shell=True, capture_output=True, text=True)
        return result.returncode == 0, result.stdout.strip(), result.stderr.strip()
    except Exception as e:
        return False, "", str(e)

def main():
    print("üöÄ Creating GitHub release with large files...")
    
    # Check if gh CLI is available
    success, _, _ = run_command("gh --version")
    if not success:
        print("‚ùå GitHub CLI (gh) not found. Please install it:")
        print("   https://cli.github.com/")
        return False
    
    # Create release
    release_notes_file = BASE_DIR / "docs" / "RELEASE_NOTES_v1.0.0.md"
    
    print(f"üìù Creating release {{RELEASE_TAG}}...")
    cmd = f'gh release create {{RELEASE_TAG}} --title "{{RELEASE_TITLE}}" --notes-file "{{release_notes_file}}"'
    success, output, error = run_command(cmd)
    
    if not success:
        print(f"‚ùå Failed to create release: {{error}}")
        return False
    
    print("‚úÖ Release created successfully")
    
    # Attach large files
    for file_info in LARGE_FILES:
        file_path = Path(file_info['path'])
        if file_path.exists():
            print(f"üìé Attaching {{file_info['name']}} ({{file_info['size_mb']}} MB)...")
            cmd = f'gh release upload {{RELEASE_TAG}} "{{file_path}}"'
            success, output, error = run_command(cmd)
            
            if success:
                print(f"   ‚úÖ Uploaded {{file_info['name']}}")
            else:
                print(f"   ‚ùå Failed to upload {{file_info['name']}}: {{error}}")
        else:
            print(f"   ‚ö†Ô∏è File not found: {{file_path}}")
    
    print("\\nüéâ Release with large files complete!")
    print(f"   üåê View release: https://github.com/NguyenTruongAnLab/estuary-type-map/releases/tag/{{RELEASE_TAG}}")
    
    return True

if __name__ == "__main__":
    main()
"""
    
    script_path = BASE_DIR / 'attach_large_files_to_release.py'
    with open(script_path, 'w', encoding='utf-8') as f:
        f.write(script_content)
    
    print(f"   ‚úÖ Created: attach_large_files_to_release.py")
    return script_path

def main():
    print("="*80)
    print("üîß LARGE FILE MANAGEMENT FOR GITHUB REPOSITORY")
    print("="*80)
    print(f"Repository: {BASE_DIR}")
    print(f"Max file size: {MAX_FILE_SIZE_MB} MB")
    
    # Step 1: Find large files
    large_files = find_large_files()
    
    if not large_files:
        print(f"\n‚úÖ No files larger than {MAX_FILE_SIZE_MB} MB found!")
        return
    
    # Step 2: Update .gitignore
    update_gitignore(large_files)
    
    # Step 3: Untrack large files
    untrack_large_files(large_files)
    
    # Step 4: Create release manifest
    manifest_path = create_release_manifest(large_files)
    
    # Step 5: Create release script
    release_script = create_release_script(large_files)
    
    # Summary
    total_size = sum(f['size_mb'] for f in large_files)
    print(f"\n{'='*80}")
    print("‚úÖ LARGE FILE MANAGEMENT COMPLETE!")
    print(f"{'='*80}")
    print(f"üìä Summary:")
    print(f"   ‚Ä¢ Files managed: {len(large_files)}")
    print(f"   ‚Ä¢ Total size: {total_size:.1f} MB")
    print(f"   ‚Ä¢ .gitignore updated")
    print(f"   ‚Ä¢ Release manifest: {manifest_path.name}")
    print(f"   ‚Ä¢ Release script: {release_script.name}")
    
    print(f"\nüöÄ Next steps:")
    print(f"   1. Review .gitignore changes: git diff .gitignore")
    print(f"   2. Commit changes: git add . && git commit -F COMMIT_MESSAGE.md")
    print(f"   3. Push: git push origin main --tags") 
    print(f"   4. Create release: python attach_large_files_to_release.py")
    
    print(f"\nüìÅ Large files (kept locally, added to release):")
    for file_info in large_files:
        print(f"   ‚Ä¢ {file_info['path']} ({file_info['size_mb']} MB)")

if __name__ == "__main__":
    main()