# ğŸ“œ Scripts Documentation â€” Project Aquarius

**Last Updated**: October 13, 2025  
**Purpose**: Complete guide to processing pipeline structure and execution

---

## ğŸ¯ Quick Start

### One Command to Rule Them All:

```powershell
# Complete pipeline (3-4.5 hours, run overnight)
python scripts/master_pipeline.py --all
```

**That's it!** This runs everything from raw data to web-ready outputs.

---

## ğŸ“‚ Folder Structure

```
scripts/
â”œâ”€â”€ master_pipeline.py           # ğŸŒŸ MASTER ORCHESTRATOR (START HERE!)
â”œâ”€â”€ README.md                    # This file
â”‚
â”œâ”€â”€ raw_data_processing/         # ğŸ“Š STAGE 1: Process raw datasets
â”‚   â”œâ”€â”€ README.md                     # Detailed folder documentation
â”‚   â”œâ”€â”€ process_grit_all_regions.py   # GRIT v0.6 (7 regions)
â”‚   â”œâ”€â”€ process_durr.py               # DÃ¼rr 2011 estuaries
â”‚   â”œâ”€â”€ process_baum.py               # Baum 2024 morphometry
â”‚   â””â”€â”€ process_globsalt_integrated.py # GlobSalt integration
â”‚
â”œâ”€â”€ ml_salinity/                 # ğŸ¤– STAGE 2: Machine learning
â”‚   â”œâ”€â”€ README.md                     # Detailed folder documentation
â”‚   â”œâ”€â”€ ml_dynqual_master_pipeline.py # ML orchestrator
â”‚   â”œâ”€â”€ ml_step1_extract_features.py  # Feature extraction
â”‚   â”œâ”€â”€ add_dynqual_to_features.py    # DynQual integration
â”‚   â”œâ”€â”€ ml_step2_train_model.py       # Train Random Forest
â”‚   â”œâ”€â”€ ml_step3_predict.py           # Predict classifications
â”‚   â””â”€â”€ ml_step4_validate_improved.py # Multi-method validation
â”‚
â”œâ”€â”€ web_optimization/            # ğŸŒ STAGE 3: Web deployment
â”‚   â”œâ”€â”€ README.md                     # Detailed folder documentation
â”‚   â”œâ”€â”€ optimize_data_final.py        # Generate web GeoJSON
â”‚   â””â”€â”€ convert_gpkg_to_geojson.py    # Format conversion
â”‚
â”œâ”€â”€ diagnostics/                 # ğŸ”§ Debugging tools (NOT in pipeline)
â”‚   â”œâ”€â”€ README.md                     # Detailed folder documentation
â”‚   â”œâ”€â”€ audit_raw_data.py             # Audit raw dataset schemas
â”‚   â”œâ”€â”€ inspect_durr_data.py          # Inspect DÃ¼rr shapefile
â”‚   â”œâ”€â”€ inspect_ml_predictions.py     # Inspect ML outputs
â”‚   â”œâ”€â”€ inspect_validation_data.py    # Validation inspection
â”‚   â”œâ”€â”€ check_features.py             # Check ML features
â”‚   â””â”€â”€ evaluate_dynqual_feasibility.py # Test DynQual
â”‚
â””â”€â”€ legacy/                      # ğŸ“¦ Old/replaced scripts (archive)
    â”œâ”€â”€ README.md
    â””â”€â”€ ... (historical files)
```

---

## ğŸ¯ Folder Overview

### ğŸ“Š raw_data_processing/
**Purpose**: Convert raw external datasets to standardized GPKG format  
**Duration**: 60-90 minutes  
**Scripts**: 4 files  
**See**: `raw_data_processing/README.md` for detailed documentation

**Key scripts**:
- `process_grit_all_regions.py` - Process 20.5M river reaches (7 regions)
- `process_durr.py` - Process 7,057 estuary catchments
- `process_baum.py` - Process 106 large estuary measurements
- `process_globsalt_integrated.py` - Integrate 270K salinity stations

**Outputs**: `data/processed/*.gpkg` (full-resolution)

---

### ğŸ¤– ml_salinity/
**Purpose**: ML-based salinity prediction for unmeasured segments  
**Duration**: 2-3 hours  
**Scripts**: 6 files (1 orchestrator + 5 steps)  
**See**: `ml_salinity/README.md` for detailed documentation

**Key script**: `ml_dynqual_master_pipeline.py` (runs entire ML workflow)

**What it does**:
1. Extract features (topology, distance, DÃ¼rr type)
2. Add DynQual physics-based predictions
3. Train Random Forest (spatial holdout validation)
4. Predict salinity for all segments
5. Multi-method validation

**Why**: GlobSalt covers only 0.7-25% of segments. ML fills the gaps.

**Outputs**: `data/processed/ml_classified/*.gpkg` + validation reports

---

### ğŸŒ web_optimization/
**Purpose**: Generate web-ready GeoJSON (<5MB each)  
**Duration**: 30 minutes  
**Scripts**: 2 files  
**See**: `web_optimization/README.md` for detailed documentation

**Key scripts**:
- `optimize_data_final.py` - Simplify geometries, filter attributes
- `convert_gpkg_to_geojson.py` - Batch GPKG â†’ GeoJSON conversion

**Optimization**: Geometry simplification, attribute filtering, file splitting

**Outputs**: `data/web/*.geojson` (web-ready, <5MB each)

---

### ğŸ”§ diagnostics/
**Purpose**: Debugging and inspection tools  
**Scripts**: 6 files  
**See**: `diagnostics/README.md` for detailed documentation

**NOT part of main pipeline!** Use only for troubleshooting.

---

### ğŸ“¦ legacy/
**Purpose**: Archive of old/replaced scripts  
**DO NOT USE** - Kept for historical reference only

---

## ğŸš€ How to Run

### Method 1: Master Script (Recommended)

```powershell
# Complete pipeline (3-4.5 hours)
python scripts/master_pipeline.py --all
```

**What it does**:
1. Runs all scripts in correct order
2. Tracks progress (Stage 1/3, 2/3, 3/3)
3. Handles errors gracefully
4. Provides final summary

---

### Method 2: Stage-by-Stage

```powershell
# Stage 1: Raw Data Processing (60-90 min)
python scripts/master_pipeline.py --stage preprocessing

# Stage 2: Machine Learning (2-3 hours)
python scripts/master_pipeline.py --stage ml

# Stage 3: Web Optimization (30 min)
python scripts/master_pipeline.py --stage web
```

---

### Method 3: Individual Folders (For Development)

```powershell
# 1. Raw Data Processing
python scripts/raw_data_processing/process_grit_all_regions.py
python scripts/raw_data_processing/process_durr.py
python scripts/raw_data_processing/process_baum.py

# 2. Machine Learning (use orchestrator!)
python scripts/ml_salinity/ml_dynqual_master_pipeline.py --all-regions

# 3. Web Optimization
python scripts/web_optimization/optimize_data_final.py
python scripts/web_optimization/convert_gpkg_to_geojson.py
```

**Note**: See folder-specific README.md files for detailed options

---

## ğŸ“‹ Detailed Documentation

Each folder has its own comprehensive README.md with:
- âœ… Script-by-script explanation
- âœ… Scientific rationale
- âœ… Usage examples
- âœ… Input/output specifications
- âœ… Common issues and solutions

**Read these for complete details:**

1. ğŸ“Š **`raw_data_processing/README.md`** - Data ingestion and standardization
2. ğŸ¤– **`ml_salinity/README.md`** - Machine learning classification pipeline
3. ğŸŒ **`web_optimization/README.md`** - Web deployment optimization
4. ğŸ”§ **`diagnostics/README.md`** - Debugging tools

---

## ğŸ¯ Common Workflows

### First-Time Setup
```powershell
# Run complete pipeline (recommended)
python scripts/master_pipeline.py --all
```

### After Adding New Raw Data
```powershell
# Reprocess affected stages
python scripts/master_pipeline.py --stage preprocessing
python scripts/master_pipeline.py --stage ml
```

### Testing ML Changes
```powershell
# Test on single region first
python scripts/ml_salinity/ml_step1_extract_features.py --region SP
python scripts/ml_salinity/ml_step2_train_model.py
python scripts/ml_salinity/ml_step4_validate_improved.py --region SP
```

### Debugging Data Issues
```powershell
# Use diagnostic tools
python scripts/diagnostics/audit_raw_data.py
python scripts/diagnostics/inspect_durr_data.py
python scripts/diagnostics/inspect_ml_predictions.py --region SP
```

---

## ğŸŒŸ Quick Reference

### master_pipeline.py - Master Orchestrator
**Purpose**: Orchestrates complete pipeline (3 stages)  
**Duration**: 3-4.5 hours

**Options**:
```powershell
# Complete pipeline
python scripts/master_pipeline.py --all

# Individual stages
python scripts/master_pipeline.py --stage preprocessing  # 60-90 min
python scripts/master_pipeline.py --stage ml             # 2-3 hours
python scripts/master_pipeline.py --stage web            # 30 min

# Skip specific steps
python scripts/master_pipeline.py --all --skip-grit
python scripts/master_pipeline.py --all --skip-training
```

---

## ğŸ“Š Output Files Structure

```
data/processed/
â”œâ”€â”€ rivers_grit_segments_classified_*.gpkg      # GRIT (7 regions)
â”œâ”€â”€ durr_estuaries.geojson                      # DÃ¼rr catchments
â”œâ”€â”€ baum_morphometry.geojson                    # Baum estuaries
â”œâ”€â”€ ml_features/features_*.parquet              # ML features
â”œâ”€â”€ ml_models/salinity_classifier_rf.pkl        # Trained model
â”œâ”€â”€ ml_classified/rivers_grit_ml_classified_*.gpkg  # Final results
â””â”€â”€ validation_improved/*.csv                   # Validation reports

data/web/
â””â”€â”€ *.geojson                                   # Web-ready (<5MB)
```

---

## âš ï¸ Key Points to Remember

### Spatial Holdout (Critical!)
- SP region is **NEVER** used in training
- Only SP provides true independent validation
- Expected accuracy: 72-78% on SP (honest assessment)

### Data Quality
- DynQual: Sanitize values >45 PSU (NetCDF fill values)
- DÃ¼rr FIN_TYP: Integer type, not strings
- GlobSalt: Covers only 0.7-25% of segments (ML fills gaps)

### System Requirements
- RAM: 16+ GB recommended
- Storage: 10+ GB for processed files
- Duration: 3-4.5 hours (complete pipeline)

---

## ğŸ†˜ Troubleshooting

### Issue: "File not found"
```powershell
python scripts/diagnostics/audit_raw_data.py  # Check raw data structure
```

### Issue: ML shows 100% accuracy
**Problem**: Data leakage!  
**Solution**: Check `holdout_region.txt` = SP, validation uses `model.predict()`

### Issue: Out of memory
**Solution**: Process regions one at a time or close other applications

### Issue: Scripts not found after reorganization
**Problem**: Old paths in custom scripts  
**Solution**: Update to use new folder structure:
- `scripts/process_grit_all_regions.py` â†’ `scripts/raw_data_processing/process_grit_all_regions.py`
- `scripts/ml_step1_extract_features.py` â†’ `scripts/ml_salinity/ml_step1_extract_features.py`
- etc.

---

## ğŸ“– Related Documentation

- **Folder READMEs**: Detailed documentation for each script group
  - `raw_data_processing/README.md`
  - `ml_salinity/README.md`
  - `web_optimization/README.md`
  - `diagnostics/README.md`

- **Project Documentation**:
  - `README.md` - Project overview
  - `docs/METHODOLOGY.md` - Scientific methods
  - `docs/TECHNICAL.md` - Technical specifications
  - `docs/OVERNIGHT_RUN_GUIDE.md` - ML pipeline guide
  - `.github/copilot-instructions.md` - Project memory bank

---

## ğŸ“ For AI Copilot Agents

When writing new Python scripts:

1. **Save to correct folder**:
   - Raw data processing â†’ `scripts/raw_data_processing/`
   - ML classification â†’ `scripts/ml_salinity/`
   - Web optimization â†’ `scripts/web_optimization/`
   - Debugging tools â†’ `scripts/diagnostics/`

2. **Update documentation**:
   - Add script description to folder README.md
   - Update `master_pipeline.py` if part of main workflow

3. **Follow naming conventions**:
   - Processing: `process_<dataset>.py`
   - ML steps: `ml_step<number>_<action>.py`
   - Diagnostics: `inspect_<target>.py` or `check_<target>.py`

---

**Questions?** Read folder-specific README.md files for complete details!

---

**That's it!** Clean, organized, and well-documented. ğŸ‰
